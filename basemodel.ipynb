{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7583a09b",
   "metadata": {},
   "source": [
    "# Implementing Biomedical NER with Multi RAG system\n",
    "\n",
    "This notebook enhances the core workflows presented in the paper **\"LLMs in Biomedical: A Study on Named Entity Recognition\"**. I will adapt the paper's methods for an open-source model, replacing the proprietary GPT-4 with **Gemini3**.\n",
    "\n",
    "The goal is to perform **Named Entity Recognition (NER)** on biomedical text, identifying entities like diseases, treatments, and tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf25b5",
   "metadata": {},
   "source": [
    "--- \n",
    "## 1. Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2685616f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:44:42.766279Z",
     "start_time": "2025-12-01T00:44:28.431068Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask.multiprocessing import exceptions\n",
    "from sklearn.externals.array_api_compat.dask.array import astype\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "from datasets import load_dataset\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import requests\n",
    "import  ast\n",
    "import re\n",
    "import ast\n",
    "\n",
    "# Check for GPU availability for faster processing\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apoor\\projects\\NLP\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "d3464c07",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Loading Models and Data\n",
    "\n",
    "Here, we load the TinyLlama chat model, the BioClinicalBERT model for embeddings."
   ]
  },
  {
   "cell_type": "code",
   "id": "8a01ebfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:44:42.823670Z",
     "start_time": "2025-12-01T00:44:42.819106Z"
    }
   },
   "source": [
    "os.getenv(\".env\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "3a8cc019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:44:58.297682Z",
     "start_time": "2025-12-01T00:44:42.842549Z"
    }
   },
   "source": [
    "# loading the tiny llama model \n",
    "pipe = pipeline('text-generation', model=\"meta-llama/Llama-3.2-3B-Instruct\", dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "# loading the BioClinicalBert model for encodings\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "print(\"Models Loaded Successfully!!\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.85s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Loaded Successfully!!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:44:58.372773Z",
     "start_time": "2025-12-01T00:44:58.363489Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "b85e04e786cf0674",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "7c6feaef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:44:58.575841Z",
     "start_time": "2025-12-01T00:44:58.467773Z"
    }
   },
   "source": [
    "# Convert data to a dataframe\n",
    "db = pd.read_csv(\"data-words/train.tsv\", sep='\\t')\n",
    "db = db.dropna()\n",
    "db"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Identification  O\n",
       "0                  of  O\n",
       "1                APC2  O\n",
       "2                   ,  O\n",
       "3                   a  O\n",
       "4           homologue  O\n",
       "...               ... ..\n",
       "135994            and  O\n",
       "135995      increased  O\n",
       "135996       survival  O\n",
       "135997              .  O\n",
       "135998              .  O\n",
       "\n",
       "[135971 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identification</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APC2</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>homologue</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135994</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135995</th>\n",
       "      <td>increased</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135996</th>\n",
       "      <td>survival</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135997</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135998</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135971 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## This function is a part of the RAG module for the DiRAG for Zero-Shot Entity identification.",
   "id": "ed71ef8a0a60aa0d"
  },
  {
   "cell_type": "code",
   "id": "2d086b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:44:58.644867Z",
     "start_time": "2025-12-01T00:44:58.635794Z"
    }
   },
   "source": [
    "\n",
    "def get_context(search_term,search_db):\n",
    "    \"\"\"This function extract the documents which are required for the context for Zero-Shot DiRAG module\"\"\"\n",
    "    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "\n",
    "    esearch_url = BASE_URL + \"esearch.fcgi\"\n",
    "\n",
    "    esearch_params = {\n",
    "        \"db\": search_db,\n",
    "        \"term\": search_term,\n",
    "        \"retmax\": 5,\n",
    "        \"retmode\": \"json\",\n",
    "        \"usehistory\": \"y\",\n",
    "        \"tool\": \"MyPubMedAPIScript\",\n",
    "        \"email\": os.getenv(\"email\"),\n",
    "        \"api_key\": os.getenv(\"ncbi_token\")\n",
    "    }\n",
    "\n",
    "    response = requests.get(esearch_url,params=esearch_params)\n",
    "    response.raise_for_status\n",
    "\n",
    "    result_json = response.json()\n",
    "\n",
    "    result = result_json.get(\"esearchresult\",{})\n",
    "    ids = result.get(\"idlist\",[])\n",
    "    count = result.get(\"count\",0)\n",
    "    webenv = result.get(\"webenv\")\n",
    "\n",
    "    final_result = {\"search term\": search_term,\n",
    "                    \"total results:\": count,\n",
    "                    \"id list\": ids,\n",
    "                    \"web environment\": webenv}\n",
    "\n",
    "\n",
    "    return final_result[\"id list\"]\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating a workflow with a small sample size",
   "id": "dea1354a02718f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Zero-Shot Entity Identification",
   "id": "e397f45111a26828"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Identification of potential entities",
   "id": "df9532c5c454c241"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:44:58.668017Z",
     "start_time": "2025-12-01T00:44:58.659889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating a database of Punctuations and stopwords to be removed for consideration for predictions\n",
    "import string\n",
    "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "punctuation_list = list(string.punctuation)\n",
    "punctuation_list.append(stopwords)\n",
    "print(punctuation_list)"
   ],
   "id": "7916f2bc358ccd88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:44:58.750975Z",
     "start_time": "2025-12-01T00:44:58.700932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating a list of prompts\n",
    "\n",
    "current_words = db[\"Identification\"].iloc[0:500]\n",
    "current_text = \" \".join(current_words)\n",
    "all_prompts = []\n",
    "for i in current_words:\n",
    "    if i not in punctuation_list:\n",
    "        prompt_first_classification = [\n",
    "          {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert in medical domain. Given the following word, your task is to identify that it could potentially be a medical term for a disease or not, do not add any other text just return the output format specified. The output should be either 'o' if the word is not a potential medical disease and 'e' if the word is a potential entity specifying a disease, the format of the output should be a dictionary: for example {'dancing': 'o'}\"\n",
    "             },\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"data: {i}\"\n",
    "            },\n",
    "            ]\n",
    "        prompt = pipe.tokenizer.apply_chat_template(prompt_first_classification, tokenize=False, add_generation_prompt=True)\n",
    "        all_prompts.append(prompt)"
   ],
   "id": "88ad89bb78c07717",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:45:41.802771Z",
     "start_time": "2025-12-01T00:44:58.763037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Passing the prompts to the LLM for initial identification of entities and adding the results to a list (test_entities_from_doc)\n",
    "pipe.tokenizer.pad_token_id = pipe.tokenizer.eos_token_id\n",
    "test_entities_from_doc = pipe(\n",
    "        all_prompts,\n",
    "        max_new_tokens=1000,\n",
    "        temperature=0.1,\n",
    "        batch_size=16,\n",
    "        return_full_text=False)"
   ],
   "id": "3fb55a760621a112",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:45:41.856719Z",
     "start_time": "2025-12-01T00:45:41.829438Z"
    }
   },
   "cell_type": "code",
   "source": "test_entities_from_doc",
   "id": "4866ff609fd31a39",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': \"assistant\\n\\n{'of': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC2': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'homologue': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'adenomatous': 'e'}\"}],\n",
       " [{'generated_text': \"{'polyposis': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'coli': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'tumour': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'suppressor': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'adenomatous': 'e'}\"}],\n",
       " [{'generated_text': \"{'polyposis': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'coli': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC': 'e'}\"}],\n",
       " [{'generated_text': \"{'tumour': 'e'}\"}],\n",
       " [{'generated_text': \"{'suppressor': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'protein': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'controls': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'Wnt': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'signalling': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'pathway': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'forming': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'glycogen': 'e'}\"}],\n",
       " [{'generated_text': \"{'synthase': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'kinase': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'3beta': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'GSK': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'3beta': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'axin': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'conductin': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'betacatenin': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'Complex': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'induces': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'rapid': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'degradation': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'betacatenin': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'In': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'colon': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'carcinoma': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'cells': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'loss': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'of': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'leads': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'accumulation': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'of': 'o'}\"}],\n",
       " [{'generated_text': \"{'betacatenin': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'nucleus': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'where': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'binds': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'activates': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'Tcf': 'e'}\"}],\n",
       " [{'generated_text': \"{'data': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'transcription': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': '{o}'}],\n",
       " [{'generated_text': '{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'Here': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'we': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'identification': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'genomic': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'structure': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC': 'e'}\"}],\n",
       " [{'generated_text': \"{'homologues': 'e'}\"}],\n",
       " [{'generated_text': \"{'Mammalian': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC2': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'resembles': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'overall': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'domain': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'structure': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'functionally': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'analyzed': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'contain': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'SAMP': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'domains': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'both': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'are': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'data': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'conductin': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC2': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'regulates': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'of': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'active': 'e'}\"}],\n",
       " [{'generated_text': \"{'betacatenin': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'Tcf': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'complexes': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'demonstrated': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'transient': 'e'}\"}],\n",
       " [{'generated_text': \"{'transcriptional': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'activation': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'assays': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'carcinoma': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'cells': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'Human': 'e'}\"}],\n",
       " [{'generated_text': \"{'APC2': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'chromosome': 'e'}\"}],\n",
       " [{'generated_text': \"{'19p13': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'APC2': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'may': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'therefore': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'comparable': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'development': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'cancer': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'common': 'o'}\"}],\n",
       " [{'generated_text': \"{'MSH2': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'mutation': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'American': 'o'}\"}],\n",
       " [{'generated_text': \"{'HNPCC': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'origin': 'o'}\"}],\n",
       " [{'generated_text': \"{'phenotypic': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'expression': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'sex': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'specific': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'differences': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'colorectal': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'cancer': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'phenotypic': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'expression': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'germline': 'e'}\"}],\n",
       " [{'generated_text': \"{'MSH2': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'gene': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'mutation': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'previously': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'identified': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'kindreds': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'hereditary': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'non': 'o'}\"}],\n",
       " [{'generated_text': \"{'polyposis': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'cancer': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'syndrome': 'e'}\"}],\n",
       " [{'generated_text': \"{'HNPCC': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'investigated': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'mutation': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'nt943': 'o'}\"}],\n",
       " [{'generated_text': '{o}'}],\n",
       " [{'generated_text': \"{'disrupts': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': '{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'exon': 'e'}\"}],\n",
       " [{'generated_text': '{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'leading': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'deletion': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'exon': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'MSH2': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'mRNA': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'represents': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'MSH2': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'mutation': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'so': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'reported': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'mutation': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'initially': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'detected': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': '{o}'}],\n",
       " [{'generated_text': \"{'colorectal': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'cancer': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'analysed': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'eastern': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'extensive': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'analysis': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'has': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'reduced': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'frequency': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'52': 'o'}\"}],\n",
       " [{'generated_text': \"{'8': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'HNPCC': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'kindreds': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'analysed': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'In': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'contrast': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'MSH2': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'mutation': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'identified': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'separately': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'identified': 'e'}\"}],\n",
       " [{'generated_text': \"{'colorectal': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'origin': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'mutation': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'colorectal': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'cancer': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'n': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'n': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'United': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'n': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'haplotype': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'analysis': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'microsatellite': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'markers': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'linked': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'MSH2': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'performed': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'Within': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'US': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'little': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'evidence': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'common': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'origin': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'of': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'MSH2': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'mutation': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'In': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'contrast': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'common': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'haplotype': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'identified': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'at': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'flanking': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'markers': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'CA5': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'D2S288': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'of': 'o'}\"}],\n",
       " [{'generated_text': \"{'the': 'o'}\"}],\n",
       " [{'generated_text': \"{'Newfoundland': 'o'}\"}],\n",
       " [{'generated_text': \"{'families': 'o'}\"}],\n",
       " [{'generated_text': \"{'These': 'o'}\"}],\n",
       " [{'generated_text': \"{'findings': 'e'}\"}],\n",
       " [{'generated_text': \"{'suggested': 'o'}\"}],\n",
       " [{'generated_text': \"{'a': 'o'}\"}],\n",
       " [{'generated_text': \"{'founder': 'o'}\"}],\n",
       " [{'generated_text': \"{'effect': 'e'}\"}],\n",
       " [{'generated_text': \"{'within': 'e'}\"}],\n",
       " [{'generated_text': \"{'Newfoundland': 'o'}\"}],\n",
       " [{'generated_text': \"{'similar': 'o'}\"}],\n",
       " [{'generated_text': \"{'to': 'o'}\"}],\n",
       " [{'generated_text': \"{'that': 'o'}\"}],\n",
       " [{'generated_text': \"{'reported': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"{'MLH1': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'mutations': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'Finnish': 'o'}\"}],\n",
       " [{'generated_text': \"{'HNPCC': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'calculated': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'age': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'related': 'o'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'risks': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'of': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'colorectal': 'e'}\"}],\n",
       " [{'generated_text': \"{'endometrial': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'ovarian': 'e'}\"}],\n",
       " [{'generated_text': \"assistant\\n\\n{'cancers': 'e'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': \"assistant\\n\\n{'nt943': 'o'}\"}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}],\n",
       " [{'generated_text': 'assistant\\n\\n{o}'}]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating chunks of the column of size 1500 and adding them to the list of prompts and Calling the pipeline for the entire sample\n",
    "(This is taking in the entire sample, I have taken a smaller sample size of 500 since working with the entire sample size takes a lot of time. Once the workflow is build, I will be using the entire sample)"
   ],
   "id": "4c957f5a15067986"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:45:41.881201Z",
     "start_time": "2025-12-01T00:45:41.877205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# chunks = 1500\n",
    "# overlap = 200\n",
    "# all_potential_entities = set()\n",
    "# all_prompts = []\n",
    "#\n",
    "# for i in range(0,len(db[\"Identification\"]),chunks-overlap):\n",
    "#\n",
    "#         current_words = db[\"Identification\"][i:i+chunks]\n",
    "#         current_text = \" \".join(current_words)\n",
    "#\n",
    "#         prompt_tanl = [\n",
    "#             {\n",
    "#               \"role\": \"system\",\n",
    "#               \"content\": \"You are an expert in medical domain. Given the following document, your task is to identify that it could potentially be a medical entity, do not add any other text just return the output format specified. The output should be a list of strings where the strings will be the potential medical entities nothing else, for example: the output format should be: ['entity 1', 'entity 2' ... and so on]\"\n",
    "#                         },\n",
    "#                 {\n",
    "#                  \"role\": \"user\",\n",
    "#                  \"content\": f\"data: {current_text}\"\n",
    "#                 },\n",
    "#                 ]\n",
    "#\n",
    "#         prompt = pipe.tokenizer.apply_chat_template(prompt_tanl, tokenize=False, add_generation_prompt=True)\n",
    "#         all_prompts.append(prompt)\n",
    "#\n",
    "# print(\"All prompts added\")\n",
    "# pipe.tokenizer.pad_token = pipe.tokenizer.eos_token\n"
   ],
   "id": "65c3dd4e2473eb50",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:45:41.920585Z",
     "start_time": "2025-12-01T00:45:41.917022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# entities_from_doc = pipe(all_prompts,\n",
    "#         max_new_tokens=1024,\n",
    "#         temperature=0.1,\n",
    "#         return_full_text=False,\n",
    "#         batch_size=8)"
   ],
   "id": "57d3bafec7825ca6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:45:41.946710Z",
     "start_time": "2025-12-01T00:45:41.933569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This code block will format the results in a dictionary format\n",
    "\n",
    "cleaned_results = []\n",
    "json_pattern = re.compile(r\"\\{.*\\}\")\n",
    "\n",
    "# We use zip() to iterate over the input words and the output results at the same time\n",
    "for original_word, item in zip(current_words, test_entities_from_doc):\n",
    "    generated_text = item[0]['generated_text']\n",
    "\n",
    "    # 1. Handle the specific Broken Case: {o}\n",
    "    # If the LLM just said {o}, we assume the tag is 'o' for the current word\n",
    "    if \"{o}\" in generated_text:\n",
    "        cleaned_results.append({'word': original_word, 'prediction': 'o'})\n",
    "        continue # Skip to next item\n",
    "\n",
    "    # 2. Handle the specific Broken Case: {e}\n",
    "    if \"{e}\" in generated_text:\n",
    "        cleaned_results.append({'word': original_word, 'prediction': 'e'})\n",
    "        continue # Skip to next item\n",
    "\n",
    "    # 3. Handle Normal Case: {'word': 'e'}\n",
    "    match = json_pattern.search(generated_text)\n",
    "    if match:\n",
    "        json_string = match.group(0)\n",
    "        try:\n",
    "            parsed_dict = ast.literal_eval(json_string)\n",
    "            predicted_label = list(parsed_dict.values())[0]\n",
    "            cleaned_results.append({'word': original_word, 'prediction': predicted_label})\n",
    "        except:\n",
    "            # If it still fails, force the original word with an error tag\n",
    "            cleaned_results.append({'word': original_word, 'prediction': 'parsing_error'})\n",
    "    else:\n",
    "        cleaned_results.append({'word': original_word, 'prediction': 'parsing_error'})\n",
    "\n",
    "print(cleaned_results)"
   ],
   "id": "c768a681e8a70eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'of', 'prediction': 'o'}, {'word': 'APC2', 'prediction': 'e'}, {'word': ',', 'prediction': 'o'}, {'word': 'a', 'prediction': 'e'}, {'word': 'homologue', 'prediction': 'o'}, {'word': 'of', 'prediction': 'o'}, {'word': 'the', 'prediction': 'e'}, {'word': 'adenomatous', 'prediction': 'e'}, {'word': 'polyposis', 'prediction': 'e'}, {'word': 'coli', 'prediction': 'e'}, {'word': 'tumour', 'prediction': 'e'}, {'word': 'suppressor', 'prediction': 'o'}, {'word': '.', 'prediction': 'e'}, {'word': 'The', 'prediction': 'e'}, {'word': 'adenomatous', 'prediction': 'e'}, {'word': 'polyposis', 'prediction': 'e'}, {'word': 'coli', 'prediction': 'e'}, {'word': '(', 'prediction': 'e'}, {'word': 'APC', 'prediction': 'e'}, {'word': ')', 'prediction': 'o'}, {'word': 'tumour', 'prediction': 'o'}, {'word': '-', 'prediction': 'e'}, {'word': 'suppressor', 'prediction': 'e'}, {'word': 'protein', 'prediction': 'e'}, {'word': 'controls', 'prediction': 'o'}, {'word': 'the', 'prediction': 'o'}, {'word': 'Wnt', 'prediction': 'o'}, {'word': 'signalling', 'prediction': 'o'}, {'word': 'pathway', 'prediction': 'o'}, {'word': 'by', 'prediction': 'e'}, {'word': 'forming', 'prediction': 'e'}, {'word': 'a', 'prediction': 'e'}, {'word': 'complex', 'prediction': 'e'}, {'word': 'with', 'prediction': 'e'}, {'word': 'glycogen', 'prediction': 'e'}, {'word': 'synthase', 'prediction': 'e'}, {'word': 'kinase', 'prediction': 'e'}, {'word': '3beta', 'prediction': 'o'}, {'word': '(', 'prediction': 'e'}, {'word': 'GSK', 'prediction': 'o'}, {'word': '-', 'prediction': 'o'}, {'word': '3beta', 'prediction': 'e'}, {'word': ')', 'prediction': 'o'}, {'word': ',', 'prediction': 'e'}, {'word': 'axin', 'prediction': 'e'}, {'word': '/', 'prediction': 'o'}, {'word': 'conductin', 'prediction': 'e'}, {'word': 'and', 'prediction': 'o'}, {'word': 'betacatenin', 'prediction': 'o'}, {'word': '.', 'prediction': 'e'}, {'word': 'Complex', 'prediction': 'e'}, {'word': 'formation', 'prediction': 'o'}, {'word': 'induces', 'prediction': 'o'}, {'word': 'the', 'prediction': 'e'}, {'word': 'rapid', 'prediction': 'o'}, {'word': 'degradation', 'prediction': 'o'}, {'word': 'of', 'prediction': 'o'}, {'word': 'betacatenin', 'prediction': 'o'}, {'word': '.', 'prediction': 'o'}, {'word': 'In', 'prediction': 'e'}, {'word': 'colon', 'prediction': 'o'}, {'word': 'carcinoma', 'prediction': 'o'}, {'word': 'cells', 'prediction': 'e'}, {'word': ',', 'prediction': 'o'}, {'word': 'loss', 'prediction': 'o'}, {'word': 'of', 'prediction': 'o'}, {'word': 'APC', 'prediction': 'o'}, {'word': 'leads', 'prediction': 'o'}, {'word': 'to', 'prediction': 'e'}, {'word': 'the', 'prediction': 'o'}, {'word': 'accumulation', 'prediction': 'e'}, {'word': 'of', 'prediction': 'o'}, {'word': 'betacatenin', 'prediction': 'e'}, {'word': 'in', 'prediction': 'o'}, {'word': 'the', 'prediction': 'o'}, {'word': 'nucleus', 'prediction': 'o'}, {'word': ',', 'prediction': 'o'}, {'word': 'where', 'prediction': 'o'}, {'word': 'it', 'prediction': 'o'}, {'word': 'binds', 'prediction': 'o'}, {'word': 'to', 'prediction': 'o'}, {'word': 'and', 'prediction': 'o'}, {'word': 'activates', 'prediction': 'e'}, {'word': 'the', 'prediction': 'o'}, {'word': 'Tcf', 'prediction': 'e'}, {'word': '-', 'prediction': 'e'}, {'word': '4', 'prediction': 'o'}, {'word': 'transcription', 'prediction': 'e'}, {'word': 'factor', 'prediction': 'e'}, {'word': '(', 'prediction': 'e'}, {'word': 'reviewed', 'prediction': 'e'}, {'word': 'in', 'prediction': 'o'}, {'word': '[', 'prediction': 'o'}, {'word': '1', 'prediction': 'o'}, {'word': ']', 'prediction': 'e'}, {'word': '[', 'prediction': 'o'}, {'word': '2', 'prediction': 'o'}, {'word': ']', 'prediction': 'e'}, {'word': ')', 'prediction': 'e'}, {'word': '.', 'prediction': 'o'}, {'word': 'Here', 'prediction': 'e'}, {'word': ',', 'prediction': 'e'}, {'word': 'we', 'prediction': 'o'}, {'word': 'report', 'prediction': 'o'}, {'word': 'the', 'prediction': 'o'}, {'word': 'identification', 'prediction': 'o'}, {'word': 'and', 'prediction': 'o'}, {'word': 'genomic', 'prediction': 'o'}, {'word': 'structure', 'prediction': 'o'}, {'word': 'of', 'prediction': 'o'}, {'word': 'APC', 'prediction': 'o'}, {'word': 'homologues', 'prediction': 'o'}, {'word': '.', 'prediction': 'o'}, {'word': 'Mammalian', 'prediction': 'o'}, {'word': 'APC2', 'prediction': 'o'}, {'word': ',', 'prediction': 'o'}, {'word': 'which', 'prediction': 'o'}, {'word': 'closely', 'prediction': 'e'}, {'word': 'resembles', 'prediction': 'o'}, {'word': 'APC', 'prediction': 'e'}, {'word': 'in', 'prediction': 'e'}, {'word': 'overall', 'prediction': 'e'}, {'word': 'domain', 'prediction': 'o'}, {'word': 'structure', 'prediction': 'o'}, {'word': ',', 'prediction': 'o'}, {'word': 'was', 'prediction': 'e'}, {'word': 'functionally', 'prediction': 'e'}, {'word': 'analyzed', 'prediction': 'e'}, {'word': 'and', 'prediction': 'e'}, {'word': 'shown', 'prediction': 'o'}, {'word': 'to', 'prediction': 'e'}, {'word': 'contain', 'prediction': 'o'}, {'word': 'two', 'prediction': 'e'}, {'word': 'SAMP', 'prediction': 'e'}, {'word': 'domains', 'prediction': 'e'}, {'word': ',', 'prediction': 'o'}, {'word': 'both', 'prediction': 'o'}, {'word': 'of', 'prediction': 'e'}, {'word': 'which', 'prediction': 'o'}, {'word': 'are', 'prediction': 'e'}, {'word': 'required', 'prediction': 'e'}, {'word': 'for', 'prediction': 'e'}, {'word': 'binding', 'prediction': 'e'}, {'word': 'to', 'prediction': 'o'}, {'word': 'conductin', 'prediction': 'o'}, {'word': '.', 'prediction': 'e'}, {'word': 'Like', 'prediction': 'e'}, {'word': 'APC', 'prediction': 'o'}, {'word': ',', 'prediction': 'e'}, {'word': 'APC2', 'prediction': 'o'}, {'word': 'regulates', 'prediction': 'e'}, {'word': 'the', 'prediction': 'o'}, {'word': 'formation', 'prediction': 'o'}, {'word': 'of', 'prediction': 'o'}, {'word': 'active', 'prediction': 'o'}, {'word': 'betacatenin', 'prediction': 'o'}, {'word': '-', 'prediction': 'o'}, {'word': 'Tcf', 'prediction': 'e'}, {'word': 'complexes', 'prediction': 'o'}, {'word': ',', 'prediction': 'e'}, {'word': 'as', 'prediction': 'o'}, {'word': 'demonstrated', 'prediction': 'o'}, {'word': 'using', 'prediction': 'e'}, {'word': 'transient', 'prediction': 'e'}, {'word': 'transcriptional', 'prediction': 'o'}, {'word': 'activation', 'prediction': 'o'}, {'word': 'assays', 'prediction': 'o'}, {'word': 'in', 'prediction': 'o'}, {'word': 'APC', 'prediction': 'o'}, {'word': '-', 'prediction': 'e'}, {'word': '/', 'prediction': 'o'}, {'word': '-', 'prediction': 'o'}, {'word': 'colon', 'prediction': 'e'}, {'word': 'carcinoma', 'prediction': 'o'}, {'word': 'cells', 'prediction': 'o'}, {'word': '.', 'prediction': 'o'}, {'word': 'Human', 'prediction': 'e'}, {'word': 'APC2', 'prediction': 'e'}, {'word': 'maps', 'prediction': 'o'}, {'word': 'to', 'prediction': 'e'}, {'word': 'chromosome', 'prediction': 'e'}, {'word': '19p13', 'prediction': 'o'}, {'word': '.', 'prediction': 'o'}, {'word': '3', 'prediction': 'o'}, {'word': '.', 'prediction': 'o'}, {'word': 'APC', 'prediction': 'e'}, {'word': 'and', 'prediction': 'o'}, {'word': 'APC2', 'prediction': 'o'}, {'word': 'may', 'prediction': 'o'}, {'word': 'therefore', 'prediction': 'e'}, {'word': 'have', 'prediction': 'e'}, {'word': 'comparable', 'prediction': 'e'}, {'word': 'functions', 'prediction': 'e'}, {'word': 'in', 'prediction': 'o'}, {'word': 'development', 'prediction': 'e'}, {'word': 'and', 'prediction': 'o'}, {'word': 'cancer', 'prediction': 'o'}, {'word': '.', 'prediction': 'o'}, {'word': 'A', 'prediction': 'o'}, {'word': 'common', 'prediction': 'e'}, {'word': 'MSH2', 'prediction': 'o'}, {'word': 'mutation', 'prediction': 'e'}, {'word': 'in', 'prediction': 'e'}, {'word': 'English', 'prediction': 'e'}, {'word': 'and', 'prediction': 'e'}, {'word': 'North', 'prediction': 'o'}, {'word': 'American', 'prediction': 'o'}, {'word': 'HNPCC', 'prediction': 'o'}, {'word': 'families', 'prediction': 'e'}, {'word': ':', 'prediction': 'o'}, {'word': 'origin', 'prediction': 'o'}, {'word': ',', 'prediction': 'o'}, {'word': 'phenotypic', 'prediction': 'o'}, {'word': 'expression', 'prediction': 'o'}, {'word': ',', 'prediction': 'e'}, {'word': 'and', 'prediction': 'o'}, {'word': 'sex', 'prediction': 'o'}, {'word': 'specific', 'prediction': 'o'}, {'word': 'differences', 'prediction': 'o'}, {'word': 'in', 'prediction': 'o'}, {'word': 'colorectal', 'prediction': 'e'}, {'word': 'cancer', 'prediction': 'o'}, {'word': '.', 'prediction': 'o'}, {'word': 'The', 'prediction': 'o'}, {'word': 'frequency', 'prediction': 'o'}, {'word': ',', 'prediction': 'o'}, {'word': 'origin', 'prediction': 'o'}, {'word': ',', 'prediction': 'o'}, {'word': 'and', 'prediction': 'e'}, {'word': 'phenotypic', 'prediction': 'o'}, {'word': 'expression', 'prediction': 'e'}, {'word': 'of', 'prediction': 'e'}, {'word': 'a', 'prediction': 'o'}, {'word': 'germline', 'prediction': 'e'}, {'word': 'MSH2', 'prediction': 'o'}, {'word': 'gene', 'prediction': 'o'}, {'word': 'mutation', 'prediction': 'o'}, {'word': 'previously', 'prediction': 'e'}, {'word': 'identified', 'prediction': 'e'}, {'word': 'in', 'prediction': 'o'}, {'word': 'seven', 'prediction': 'o'}, {'word': 'kindreds', 'prediction': 'o'}, {'word': 'with', 'prediction': 'o'}, {'word': 'hereditary', 'prediction': 'o'}, {'word': 'non', 'prediction': 'e'}, {'word': '-', 'prediction': 'o'}, {'word': 'polyposis', 'prediction': 'o'}, {'word': 'cancer', 'prediction': 'e'}, {'word': 'syndrome', 'prediction': 'o'}, {'word': '(', 'prediction': 'o'}, {'word': 'HNPCC', 'prediction': 'o'}, {'word': ')', 'prediction': 'o'}, {'word': 'was', 'prediction': 'e'}, {'word': 'investigated', 'prediction': 'e'}, {'word': '.', 'prediction': 'o'}, {'word': 'The', 'prediction': 'e'}, {'word': 'mutation', 'prediction': 'o'}, {'word': '(', 'prediction': 'o'}, {'word': 'A', 'prediction': 'o'}, {'word': '-', 'prediction': 'o'}, {'word': '-', 'prediction': 'e'}, {'word': '>', 'prediction': 'e'}, {'word': 'T', 'prediction': 'o'}, {'word': 'at', 'prediction': 'o'}, {'word': 'nt943', 'prediction': 'o'}, {'word': '+', 'prediction': 'o'}, {'word': '3', 'prediction': 'o'}, {'word': ')', 'prediction': 'o'}, {'word': 'disrupts', 'prediction': 'o'}, {'word': 'the', 'prediction': 'o'}, {'word': '3', 'prediction': 'o'}, {'word': 'splice', 'prediction': 'o'}, {'word': 'site', 'prediction': 'e'}, {'word': 'of', 'prediction': 'o'}, {'word': 'exon', 'prediction': 'e'}, {'word': '5', 'prediction': 'o'}, {'word': 'leading', 'prediction': 'e'}, {'word': 'to', 'prediction': 'o'}, {'word': 'the', 'prediction': 'e'}, {'word': 'deletion', 'prediction': 'e'}, {'word': 'of', 'prediction': 'o'}, {'word': 'this', 'prediction': 'e'}, {'word': 'exon', 'prediction': 'o'}, {'word': 'from', 'prediction': 'o'}, {'word': 'MSH2', 'prediction': 'o'}, {'word': 'mRNA', 'prediction': 'o'}, {'word': 'and', 'prediction': 'o'}, {'word': 'represents', 'prediction': 'o'}, {'word': 'the', 'prediction': 'e'}, {'word': 'only', 'prediction': 'e'}, {'word': 'frequent', 'prediction': 'o'}, {'word': 'MSH2', 'prediction': 'o'}, {'word': 'mutation', 'prediction': 'o'}, {'word': 'so', 'prediction': 'o'}, {'word': 'far', 'prediction': 'o'}, {'word': 'reported', 'prediction': 'o'}, {'word': '.', 'prediction': 'o'}, {'word': 'Although', 'prediction': 'o'}, {'word': 'this', 'prediction': 'o'}, {'word': 'mutation', 'prediction': 'e'}, {'word': 'was', 'prediction': 'o'}, {'word': 'initially', 'prediction': 'e'}, {'word': 'detected', 'prediction': 'e'}, {'word': 'in', 'prediction': 'o'}, {'word': 'four', 'prediction': 'o'}, {'word': 'of', 'prediction': 'o'}, {'word': '33', 'prediction': 'o'}, {'word': 'colorectal', 'prediction': 'o'}, {'word': 'cancer', 'prediction': 'o'}, {'word': 'families', 'prediction': 'o'}, {'word': 'analysed', 'prediction': 'o'}, {'word': 'from', 'prediction': 'o'}, {'word': 'eastern', 'prediction': 'o'}, {'word': 'England', 'prediction': 'o'}, {'word': ',', 'prediction': 'o'}, {'word': 'more', 'prediction': 'o'}, {'word': 'extensive', 'prediction': 'o'}, {'word': 'analysis', 'prediction': 'e'}, {'word': 'has', 'prediction': 'e'}, {'word': 'reduced', 'prediction': 'o'}, {'word': 'the', 'prediction': 'e'}, {'word': 'frequency', 'prediction': 'e'}, {'word': 'to', 'prediction': 'o'}, {'word': 'four', 'prediction': 'o'}, {'word': 'of', 'prediction': 'e'}, {'word': '52', 'prediction': 'o'}, {'word': '(', 'prediction': 'e'}, {'word': '8', 'prediction': 'e'}, {'word': '%', 'prediction': 'o'}, {'word': ')', 'prediction': 'o'}, {'word': 'English', 'prediction': 'o'}, {'word': 'HNPCC', 'prediction': 'o'}, {'word': 'kindreds', 'prediction': 'o'}, {'word': 'analysed', 'prediction': 'o'}, {'word': '.', 'prediction': 'o'}, {'word': 'In', 'prediction': 'o'}, {'word': 'contrast', 'prediction': 'e'}, {'word': ',', 'prediction': 'o'}, {'word': 'the', 'prediction': 'o'}, {'word': 'MSH2', 'prediction': 'o'}, {'word': 'mutation', 'prediction': 'o'}, {'word': 'was', 'prediction': 'o'}, {'word': 'identified', 'prediction': 'o'}, {'word': 'in', 'prediction': 'o'}, {'word': '10', 'prediction': 'e'}, {'word': 'of', 'prediction': 'o'}, {'word': '20', 'prediction': 'o'}, {'word': '(', 'prediction': 'e'}, {'word': '50', 'prediction': 'o'}, {'word': '%', 'prediction': 'o'}, {'word': ')', 'prediction': 'o'}, {'word': 'separately', 'prediction': 'o'}, {'word': 'identified', 'prediction': 'e'}, {'word': 'colorectal', 'prediction': 'o'}, {'word': 'families', 'prediction': 'o'}, {'word': 'from', 'prediction': 'e'}, {'word': 'Newfoundland', 'prediction': 'o'}, {'word': '.', 'prediction': 'e'}, {'word': 'To', 'prediction': 'o'}, {'word': 'investigate', 'prediction': 'o'}, {'word': 'the', 'prediction': 'o'}, {'word': 'origin', 'prediction': 'e'}, {'word': 'of', 'prediction': 'e'}, {'word': 'this', 'prediction': 'e'}, {'word': 'mutation', 'prediction': 'o'}, {'word': 'in', 'prediction': 'e'}, {'word': 'colorectal', 'prediction': 'o'}, {'word': 'cancer', 'prediction': 'o'}, {'word': 'families', 'prediction': 'o'}, {'word': 'from', 'prediction': 'o'}, {'word': 'England', 'prediction': 'o'}, {'word': '(', 'prediction': 'o'}, {'word': 'n', 'prediction': 'o'}, {'word': '=', 'prediction': 'e'}, {'word': '4', 'prediction': 'o'}, {'word': ')', 'prediction': 'o'}, {'word': ',', 'prediction': 'o'}, {'word': 'Newfoundland', 'prediction': 'e'}, {'word': '(', 'prediction': 'e'}, {'word': 'n', 'prediction': 'o'}, {'word': '=', 'prediction': 'o'}, {'word': '10', 'prediction': 'o'}, {'word': ')', 'prediction': 'o'}, {'word': ',', 'prediction': 'o'}, {'word': 'and', 'prediction': 'o'}, {'word': 'the', 'prediction': 'o'}, {'word': 'United', 'prediction': 'o'}, {'word': 'States', 'prediction': 'o'}, {'word': '(', 'prediction': 'e'}, {'word': 'n', 'prediction': 'e'}, {'word': '=', 'prediction': 'o'}, {'word': '3', 'prediction': 'o'}, {'word': ')', 'prediction': 'e'}, {'word': ',', 'prediction': 'o'}, {'word': 'haplotype', 'prediction': 'o'}, {'word': 'analysis', 'prediction': 'o'}, {'word': 'using', 'prediction': 'e'}, {'word': 'microsatellite', 'prediction': 'o'}, {'word': 'markers', 'prediction': 'e'}, {'word': 'linked', 'prediction': 'o'}, {'word': 'to', 'prediction': 'o'}, {'word': 'MSH2', 'prediction': 'e'}, {'word': 'was', 'prediction': 'e'}, {'word': 'performed', 'prediction': 'o'}, {'word': '.', 'prediction': 'e'}, {'word': 'Within', 'prediction': 'e'}, {'word': 'the', 'prediction': 'o'}, {'word': 'English', 'prediction': 'o'}, {'word': 'and', 'prediction': 'o'}, {'word': 'US', 'prediction': 'o'}]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:45:42.021795Z",
     "start_time": "2025-12-01T00:45:42.003169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cleaned_results = np.array(cleaned_results)\n",
    "db_temp = pd.DataFrame(cleaned_results)\n",
    "words_for_rag = []\n",
    "for i in range(0,len(db_temp)):\n",
    "    if db_temp[\"prediction\"].iloc[i]  == \"e\" and db_temp[\"prediction\"].iloc[i] not in punctuation_list:\n",
    "        words_for_rag.append(db_temp[\"word\"].iloc[i])\n",
    "\n",
    "words_for_rag\n"
   ],
   "id": "87e5515b8ea66631",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APC2',\n",
       " 'a',\n",
       " 'the',\n",
       " 'adenomatous',\n",
       " 'polyposis',\n",
       " 'coli',\n",
       " 'tumour',\n",
       " '.',\n",
       " 'The',\n",
       " 'adenomatous',\n",
       " 'polyposis',\n",
       " 'coli',\n",
       " '(',\n",
       " 'APC',\n",
       " '-',\n",
       " 'suppressor',\n",
       " 'protein',\n",
       " 'by',\n",
       " 'forming',\n",
       " 'a',\n",
       " 'complex',\n",
       " 'with',\n",
       " 'glycogen',\n",
       " 'synthase',\n",
       " 'kinase',\n",
       " '(',\n",
       " '3beta',\n",
       " ',',\n",
       " 'axin',\n",
       " 'conductin',\n",
       " '.',\n",
       " 'Complex',\n",
       " 'the',\n",
       " 'In',\n",
       " 'cells',\n",
       " 'to',\n",
       " 'accumulation',\n",
       " 'betacatenin',\n",
       " 'activates',\n",
       " 'Tcf',\n",
       " '-',\n",
       " 'transcription',\n",
       " 'factor',\n",
       " '(',\n",
       " 'reviewed',\n",
       " ']',\n",
       " ']',\n",
       " ')',\n",
       " 'Here',\n",
       " ',',\n",
       " 'closely',\n",
       " 'APC',\n",
       " 'in',\n",
       " 'overall',\n",
       " 'was',\n",
       " 'functionally',\n",
       " 'analyzed',\n",
       " 'and',\n",
       " 'to',\n",
       " 'two',\n",
       " 'SAMP',\n",
       " 'domains',\n",
       " 'of',\n",
       " 'are',\n",
       " 'required',\n",
       " 'for',\n",
       " 'binding',\n",
       " '.',\n",
       " 'Like',\n",
       " ',',\n",
       " 'regulates',\n",
       " 'Tcf',\n",
       " ',',\n",
       " 'using',\n",
       " 'transient',\n",
       " '-',\n",
       " 'colon',\n",
       " 'Human',\n",
       " 'APC2',\n",
       " 'to',\n",
       " 'chromosome',\n",
       " 'APC',\n",
       " 'therefore',\n",
       " 'have',\n",
       " 'comparable',\n",
       " 'functions',\n",
       " 'development',\n",
       " 'common',\n",
       " 'mutation',\n",
       " 'in',\n",
       " 'English',\n",
       " 'and',\n",
       " 'families',\n",
       " ',',\n",
       " 'colorectal',\n",
       " 'and',\n",
       " 'expression',\n",
       " 'of',\n",
       " 'germline',\n",
       " 'previously',\n",
       " 'identified',\n",
       " 'non',\n",
       " 'cancer',\n",
       " 'was',\n",
       " 'investigated',\n",
       " 'The',\n",
       " '-',\n",
       " '>',\n",
       " 'site',\n",
       " 'exon',\n",
       " 'leading',\n",
       " 'the',\n",
       " 'deletion',\n",
       " 'this',\n",
       " 'the',\n",
       " 'only',\n",
       " 'mutation',\n",
       " 'initially',\n",
       " 'detected',\n",
       " 'analysis',\n",
       " 'has',\n",
       " 'the',\n",
       " 'frequency',\n",
       " 'of',\n",
       " '(',\n",
       " '8',\n",
       " 'contrast',\n",
       " '10',\n",
       " '(',\n",
       " 'identified',\n",
       " 'from',\n",
       " '.',\n",
       " 'origin',\n",
       " 'of',\n",
       " 'this',\n",
       " 'in',\n",
       " '=',\n",
       " 'Newfoundland',\n",
       " '(',\n",
       " '(',\n",
       " 'n',\n",
       " ')',\n",
       " 'using',\n",
       " 'markers',\n",
       " 'MSH2',\n",
       " 'was',\n",
       " '.',\n",
       " 'Within']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Implementing the RAG based entity identification",
   "id": "7488c5a7cbcbb97f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## This is the final iteration of LLM trying to identify entities in Zero-Shot method.\n",
    "### 1. This function will first look up the word in Pubmed database and find the Ids of the context of the word.\n",
    "### 2. It will then validate the id's.\n",
    "### 3. It will then find the xml document associated with that id and add it to the content to be passed in the final prompt.\n",
    "### 4. It will then create the final prompt with the word and the context of the word extracted from Pubmed database.\n",
    "### 5. Finally the prompt will be passed to the LLM and a final prediction will be obtained.\n"
   ],
   "id": "638e630215931fd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:45:42.067159Z",
     "start_time": "2025-12-01T00:45:42.055012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Bio import Entrez\n",
    "from urllib.error import HTTPError\n",
    "Entrez.email = \"atripathi2024@fau.edu\""
   ],
   "id": "1bfbb36365d6083d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:58:42.543188Z",
     "start_time": "2025-12-01T00:58:42.533878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def get_context_xml(test_result_preclassification, max_tokens=500):\n",
    "    \"\"\"This function will input the results from the preclassification and it will search for the ids of the words, It will then retreive the context in the form of xml which will be added to an array and an array with context will be returned\"\"\"\n",
    "    context_array = []\n",
    "    for i in test_result_preclassification:\n",
    "\n",
    "       if i not in punctuation_list:\n",
    "         search_term = i\n",
    "         ids = get_context(i,\"pubmed\")\n",
    "         valid_ids = [str(j) for j in ids if j]\n",
    "         context_xml = \"\"\n",
    "         if valid_ids:\n",
    "             try:\n",
    "                 list_of_ids = \",\".join(valid_ids[:5])\n",
    "                 handle = Entrez.efetch(db=\"pubmed\", id=list_of_ids, retmode=\"xml\")\n",
    "                 context_xml = handle.read()\n",
    "                 handle.close()\n",
    "                 if isinstance(context_xml, bytes):\n",
    "                     text = context_xml.decode('utf-8', errors='ignore')\n",
    "                 else:\n",
    "                     text = context_xml\n",
    "                 clean_text = re.sub(r'<[^>]+>', ' ', text)           # strip tags\n",
    "                 clean_text = re.sub(r'\\s+', ' ', clean_text).strip() # normalize spaces\n",
    "                 tokens = tokenizer.encode(clean_text)\n",
    "                 if len(tokens) > max_tokens:\n",
    "                    tokens = tokens[:max_tokens]\n",
    "                 context_xml = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "\n",
    "             except HTTPError as e:\n",
    "                 print(f\"HTTP Error fetching IDs for term '{search_term}': {e}\")\n",
    "                 pass\n",
    "             except Exception as e:\n",
    "                 print(f\"An error occurred for term '{search_term}': {e}\")\n",
    "                 pass\n",
    "       else:\n",
    "          context_xml = \"not a word\"\n",
    "       context_array.append(context_xml)\n",
    "\n",
    "\n",
    "\n",
    "    return  context_array\n",
    "\n",
    "\n"
   ],
   "id": "1ab3caac0770f288",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:45:42.113007Z",
     "start_time": "2025-12-01T00:45:42.108297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_final_prompts(word_list,context):\n",
    "    \"\"\"This function will input the context array and the words array and will return a list of final prompts which will contain the prompt and the context for the final prediction in Zero-Shot prediction.\"\"\"\n",
    "    all_prompts = []\n",
    "    for i in range(0,len(word_list)-1):\n",
    "        prompt_final_classification = [\n",
    "               {\n",
    "                 \"role\": \"system\",\n",
    "                  \"content\": \"You are an expert in medical domain. Given the following word, and a context which has been taken from Pubmed clinical     database, your task is to identify that it could potentially be a medical disease word or not, consider those words which are even closely related, do not add any other text just return the output format specified. The prediction should be either 'o'- which     represents outside clinical term  (for non clinical terms), 'B-CLINICAL'- for the words which are beginning of a clinical disease     term and 'I-CLINICAL' - for the words which  can be a subset of a clinical disease term, and the output format should be  a dictionary: for example {'dancing': 'o'}, where the key is the searched word and value is the prediction\"\n",
    "               },\n",
    "               {\n",
    "                  \"role\": \"user\",\n",
    "                  \"content\": f\"word: {word_list[i]}, context: {context[i]}\"\n",
    "               },\n",
    "               ]\n",
    "        all_prompts.append(prompt_final_classification)\n",
    "\n",
    "    return all_prompts"
   ],
   "id": "e947bbb50b010b73",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T01:01:31.219876Z",
     "start_time": "2025-12-01T00:58:48.115204Z"
    }
   },
   "cell_type": "code",
   "source": "context = get_context_xml(words_for_rag) # Calling the function for context",
   "id": "c2bd42f94bef1010",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:54:43.839011Z",
     "start_time": "2025-12-01T00:54:43.833027Z"
    }
   },
   "cell_type": "code",
   "source": "prompts_final = create_final_prompts(words_for_rag,context) # Calling the function for final prompts",
   "id": "5373a5285a73ea38",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:54:50.991601Z",
     "start_time": "2025-12-01T00:54:50.981561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load model in 4-bit to fit in 8GB VRAM\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,  # <--- CRITICAL FIX\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "final_output = pipe(prompts_final,\n",
    "                     max_new_tokens=1000,\n",
    "                     temperature=0.1,\n",
    "                     return_full_text=False,\n",
    "                     batch_size=16\n",
    "                     )\n",
    "# final_result = output[0][\"generated_text\"]\n",
    "# print(test_result)"
   ],
   "id": "abe0465ca28eadb5",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T01:22:17.021977Z",
     "start_time": "2025-12-01T01:05:19.738150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe.tokenizer.pad_token_id = pipe.tokenizer.eos_token_id\n",
    "final_output = pipe(\n",
    "        prompts_final,\n",
    "        max_new_tokens=1000,\n",
    "        temperature=0.1,\n",
    "        batch_size=16,\n",
    "        return_full_text=False)"
   ],
   "id": "2a76bc8a08790d1d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x0000020A4C4D5A90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\apoor\\projects\\NLP\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 796, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "  File \"C:\\Users\\apoor\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\threading.py\", line 1479, in enumerate\n",
      "    def enumerate():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m pipe.tokenizer.pad_token_id = pipe.tokenizer.eos_token_id\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m final_output = \u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprompts_final\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_full_text\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:331\u001B[39m, in \u001B[36mTextGenerationPipeline.__call__\u001B[39m\u001B[34m(self, text_inputs, **kwargs)\u001B[39m\n\u001B[32m    329\u001B[39m                 \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__call__\u001B[39m(chats, **kwargs)\n\u001B[32m    330\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m331\u001B[39m                 \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mchats\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    332\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__call__\u001B[39m(text_inputs, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1448\u001B[39m, in \u001B[36mPipeline.__call__\u001B[39m\u001B[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[39m\n\u001B[32m   1444\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m can_use_iterator:\n\u001B[32m   1445\u001B[39m     final_iterator = \u001B[38;5;28mself\u001B[39m.get_iterator(\n\u001B[32m   1446\u001B[39m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001B[32m   1447\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1448\u001B[39m     outputs = \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfinal_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n\u001B[32m   1450\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:126\u001B[39m, in \u001B[36mPipelineIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    123\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.loader_batch_item()\n\u001B[32m    125\u001B[39m \u001B[38;5;66;03m# We're out of items within a batch\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m126\u001B[39m item = \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    127\u001B[39m processed = \u001B[38;5;28mself\u001B[39m.infer(item, **\u001B[38;5;28mself\u001B[39m.params)\n\u001B[32m    128\u001B[39m \u001B[38;5;66;03m# We now have a batch of \"inferred things\".\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:127\u001B[39m, in \u001B[36mPipelineIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    125\u001B[39m \u001B[38;5;66;03m# We're out of items within a batch\u001B[39;00m\n\u001B[32m    126\u001B[39m item = \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m.iterator)\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m processed = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minfer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[38;5;66;03m# We now have a batch of \"inferred things\".\u001B[39;00m\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.loader_batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    130\u001B[39m     \u001B[38;5;66;03m# Try to infer the size of the batch\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1374\u001B[39m, in \u001B[36mPipeline.forward\u001B[39m\u001B[34m(self, model_inputs, **forward_params)\u001B[39m\n\u001B[32m   1372\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[32m   1373\u001B[39m         model_inputs = \u001B[38;5;28mself\u001B[39m._ensure_tensor_on_device(model_inputs, device=\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m-> \u001B[39m\u001B[32m1374\u001B[39m         model_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1375\u001B[39m         model_outputs = \u001B[38;5;28mself\u001B[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m   1376\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:432\u001B[39m, in \u001B[36mTextGenerationPipeline._forward\u001B[39m\u001B[34m(self, model_inputs, **generate_kwargs)\u001B[39m\n\u001B[32m    429\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mgeneration_config\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m generate_kwargs:\n\u001B[32m    430\u001B[39m     generate_kwargs[\u001B[33m\"\u001B[39m\u001B[33mgeneration_config\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28mself\u001B[39m.generation_config\n\u001B[32m--> \u001B[39m\u001B[32m432\u001B[39m output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mgenerate_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    434\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, ModelOutput):\n\u001B[32m    435\u001B[39m     generated_sequence = output.sequences\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    113\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2539\u001B[39m, in \u001B[36mGenerationMixin.generate\u001B[39m\u001B[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001B[39m\n\u001B[32m   2528\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m GenerationMixin.generate(\n\u001B[32m   2529\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   2530\u001B[39m         inputs,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2534\u001B[39m         **kwargs,\n\u001B[32m   2535\u001B[39m     )\n\u001B[32m   2537\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode.SAMPLE, GenerationMode.GREEDY_SEARCH):\n\u001B[32m   2538\u001B[39m     \u001B[38;5;66;03m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2539\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2540\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2541\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2542\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2543\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgeneration_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2544\u001B[39m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[43m=\u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2545\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2546\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2547\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2549\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;129;01min\u001B[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001B[32m   2550\u001B[39m     \u001B[38;5;66;03m# 11. run beam sample\u001B[39;00m\n\u001B[32m   2551\u001B[39m     result = \u001B[38;5;28mself\u001B[39m._beam_search(\n\u001B[32m   2552\u001B[39m         input_ids,\n\u001B[32m   2553\u001B[39m         logits_processor=prepared_logits_processor,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2557\u001B[39m         **model_kwargs,\n\u001B[32m   2558\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2870\u001B[39m, in \u001B[36mGenerationMixin._sample\u001B[39m\u001B[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001B[39m\n\u001B[32m   2868\u001B[39m     is_prefill = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m   2869\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2870\u001B[39m     outputs = \u001B[43mmodel_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   2872\u001B[39m \u001B[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001B[39;00m\n\u001B[32m   2873\u001B[39m model_kwargs = \u001B[38;5;28mself\u001B[39m._update_model_kwargs_for_generation(\n\u001B[32m   2874\u001B[39m     outputs,\n\u001B[32m   2875\u001B[39m     model_kwargs,\n\u001B[32m   2876\u001B[39m     is_encoder_decoder=\u001B[38;5;28mself\u001B[39m.config.is_encoder_decoder,\n\u001B[32m   2877\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:940\u001B[39m, in \u001B[36mcan_return_tuple.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    938\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m return_dict_passed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    939\u001B[39m     return_dict = return_dict_passed\n\u001B[32m--> \u001B[39m\u001B[32m940\u001B[39m output = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    941\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[32m    942\u001B[39m     output = output.to_tuple()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:459\u001B[39m, in \u001B[36mLlamaForCausalLM.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001B[39m\n\u001B[32m    427\u001B[39m \u001B[38;5;129m@can_return_tuple\u001B[39m\n\u001B[32m    428\u001B[39m \u001B[38;5;129m@auto_docstring\u001B[39m\n\u001B[32m    429\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m   (...)\u001B[39m\u001B[32m    440\u001B[39m     **kwargs: Unpack[TransformersKwargs],\n\u001B[32m    441\u001B[39m ) -> CausalLMOutputWithPast:\n\u001B[32m    442\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    443\u001B[39m \u001B[33;03m    Example:\u001B[39;00m\n\u001B[32m    444\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    457\u001B[39m \u001B[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001B[39;00m\n\u001B[32m    458\u001B[39m \u001B[33;03m    ```\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m459\u001B[39m     outputs: BaseModelOutputWithPast = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    460\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    462\u001B[39m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    463\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    464\u001B[39m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    465\u001B[39m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    466\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    467\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    468\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    470\u001B[39m     hidden_states = outputs.last_hidden_state\n\u001B[32m    471\u001B[39m     \u001B[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\utils\\generic.py:1064\u001B[39m, in \u001B[36mcheck_model_inputs.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1061\u001B[39m                 module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n\u001B[32m   1062\u001B[39m                 monkey_patched_layers.append((module, original_forward))\n\u001B[32m-> \u001B[39m\u001B[32m1064\u001B[39m outputs = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1065\u001B[39m \u001B[38;5;66;03m# Restore original forward methods\u001B[39;00m\n\u001B[32m   1066\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m module, original_forward \u001B[38;5;129;01min\u001B[39;00m monkey_patched_layers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:395\u001B[39m, in \u001B[36mLlamaModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001B[39m\n\u001B[32m    392\u001B[39m position_embeddings = \u001B[38;5;28mself\u001B[39m.rotary_emb(hidden_states, position_ids)\n\u001B[32m    394\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m decoder_layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.layers[: \u001B[38;5;28mself\u001B[39m.config.num_hidden_layers]:\n\u001B[32m--> \u001B[39m\u001B[32m395\u001B[39m     hidden_states = \u001B[43mdecoder_layer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    396\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    397\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    398\u001B[39m \u001B[43m        \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    399\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    400\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    401\u001B[39m \u001B[43m        \u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_embeddings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    402\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    405\u001B[39m hidden_states = \u001B[38;5;28mself\u001B[39m.norm(hidden_states)\n\u001B[32m    406\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m BaseModelOutputWithPast(\n\u001B[32m    407\u001B[39m     last_hidden_state=hidden_states,\n\u001B[32m    408\u001B[39m     past_key_values=past_key_values,\n\u001B[32m    409\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001B[39m, in \u001B[36mGradientCheckpointingLayer.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     91\u001B[39m         logger.warning_once(message)\n\u001B[32m     93\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(partial(\u001B[38;5;28msuper\u001B[39m().\u001B[34m__call__\u001B[39m, **kwargs), *args)\n\u001B[32m---> \u001B[39m\u001B[32m94\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001B[39m, in \u001B[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m minimum_action \u001B[38;5;129;01min\u001B[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torchdynamo_compiling():\n\u001B[32m    169\u001B[39m     \u001B[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001B[39;00m\n\u001B[32m    170\u001B[39m     warnings.warn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel=\u001B[32m2\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:308\u001B[39m, in \u001B[36mLlamaDecoderLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001B[39m\n\u001B[32m    306\u001B[39m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n\u001B[32m    307\u001B[39m residual = hidden_states\n\u001B[32m--> \u001B[39m\u001B[32m308\u001B[39m hidden_states = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpost_attention_layernorm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    309\u001B[39m hidden_states = \u001B[38;5;28mself\u001B[39m.mlp(hidden_states)\n\u001B[32m    310\u001B[39m hidden_states = residual + hidden_states\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\NLP\\.venv\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:66\u001B[39m, in \u001B[36mLlamaRMSNorm.forward\u001B[39m\u001B[34m(self, hidden_states)\u001B[39m\n\u001B[32m     64\u001B[39m hidden_states = hidden_states.to(torch.float32)\n\u001B[32m     65\u001B[39m variance = hidden_states.pow(\u001B[32m2\u001B[39m).mean(-\u001B[32m1\u001B[39m, keepdim=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m hidden_states = hidden_states * \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrsqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvariance\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mvariance_epsilon\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.weight * hidden_states.to(input_dtype)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T02:13:23.749524Z",
     "start_time": "2025-12-01T02:13:23.224660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This code block will format the results in a dictionary format\n",
    "\n",
    "cleaned_final_results = []\n",
    "json_pattern = re.compile(r\"\\{.*\\}\")\n",
    "\n",
    "# We use zip() to iterate over the input words and the output results at the same time\n",
    "for original_word, item in zip(current_words, final_output):\n",
    "    generated_text = item[0]['generated_text']\n",
    "\n",
    "    # 1. Handle the specific Broken Case: {o}\n",
    "    # If the LLM just said {o}, we assume the tag is 'o' for the current word\n",
    "    if \"{o}\" in generated_text:\n",
    "        cleaned_final_results.append({'word': original_word, 'prediction': 'o'})\n",
    "        continue # Skip to next item\n",
    "\n",
    "    # 2. Handle the specific Broken Case: {e}\n",
    "    if \"{e}\" in generated_text:\n",
    "        cleaned_final_results.append({'word': original_word, 'prediction': 'e'})\n",
    "        continue # Skip to next item\n",
    "\n",
    "    # 3. Handle Normal Case: {'word': 'e'}\n",
    "    match = json_pattern.search(generated_text)\n",
    "    if match:\n",
    "        json_string = match.group(0)\n",
    "        try:\n",
    "            parsed_dict = ast.literal_eval(json_string)\n",
    "            predicted_label = list(parsed_dict.values())[0]\n",
    "            cleaned_final_results.append({'word': original_word, 'prediction': predicted_label})\n",
    "        except:\n",
    "            # If it still fails, force the original word with an error tag\n",
    "            cleaned_final_results.append({'word': original_word, 'prediction': 'parsing_error'})\n",
    "    else:\n",
    "        cleaned_final_results.append({'word': original_word, 'prediction': 'parsing_error'})\n"
   ],
   "id": "62d2a4e0207173d3",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      4\u001B[39m json_pattern = re.compile(\u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\\\u001B[39m\u001B[33m{\u001B[39m\u001B[33m.*\u001B[39m\u001B[33m\\\u001B[39m\u001B[33m}\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      6\u001B[39m \u001B[38;5;66;03m# We use zip() to iterate over the input words and the output results at the same time\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m original_word, item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(current_words, \u001B[43mfinal_output\u001B[49m):\n\u001B[32m      8\u001B[39m     generated_text = item[\u001B[32m0\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mgenerated_text\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     10\u001B[39m     \u001B[38;5;66;03m# 1. Handle the specific Broken Case: {o}\u001B[39;00m\n\u001B[32m     11\u001B[39m     \u001B[38;5;66;03m# If the LLM just said {o}, we assume the tag is 'o' for the current word\u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'final_output' is not defined"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:51:06.593553400Z",
     "start_time": "2025-11-30T02:06:10.245066Z"
    }
   },
   "cell_type": "code",
   "source": "print(cleaned_final_results)",
   "id": "2a3838ed8d646f16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}, {nan: 'I-CLINICAL'}, {nan: 'B'}, {nan: 'B'}, {nan: 'B'}]\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T00:51:06.595552100Z",
     "start_time": "2025-11-29T23:20:27.669766Z"
    }
   },
   "cell_type": "code",
   "source": "db_predicted =  pd.DataFrame(cleaned_final_results)",
   "id": "9aae6ae0d17b5b25",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Term Classification\n",
       "0   NaN     I-CLINICAL\n",
       "1   NaN              B\n",
       "2   NaN              B\n",
       "3   NaN              B\n",
       "4   NaN              B"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "db_predicted",
   "id": "949bf468dd587b81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
