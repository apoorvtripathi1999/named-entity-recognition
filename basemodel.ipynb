{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7583a09b",
   "metadata": {},
   "source": [
    "# Implementing Biomedical NER with TinyLlama \n",
    "\n",
    "This notebook implements the core workflows presented in the paper **\"LLMs in Biomedical: A Study on Named Entity Recognition\"**. I will adapt the paper's methods for an open-source model, replacing the proprietary GPT-4 with **TinyLlama**.\n",
    "\n",
    "The goal is to perform **Named Entity Recognition (NER)** on biomedical text, identifying entities like diseases, treatments, and tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf25b5",
   "metadata": {},
   "source": [
    "--- \n",
    "## 1. Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2685616f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T02:15:37.182146Z",
     "start_time": "2025-10-27T02:15:37.178305Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask.multiprocessing import exceptions\n",
    "from sklearn.externals.array_api_compat.dask.array import astype\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "from datasets import load_dataset\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import requests\n",
    "import  ast\n",
    "\n",
    "# Check for GPU availability for faster processing\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "d3464c07",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Loading Models and Data\n",
    "\n",
    "Here, we load the TinyLlama chat model, the BioClinicalBERT model for embeddings."
   ]
  },
  {
   "cell_type": "code",
   "id": "8a01ebfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T02:15:37.201936Z",
     "start_time": "2025-10-27T02:15:37.199007Z"
    }
   },
   "source": [
    "os.getenv(\".env\")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "3a8cc019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T02:15:48.462985Z",
     "start_time": "2025-10-27T02:15:37.225508Z"
    }
   },
   "source": [
    "# loading the tiny llama model \n",
    "pipe = pipeline('text-generation', model=\"meta-llama/Llama-3.2-3B-Instruct\", dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "# loading the BioClinicalBert model for encodings\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "print(\"Models Loaded Successfully!!\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.16s/it]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Loaded Successfully!!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T02:15:48.501514Z",
     "start_time": "2025-10-27T02:15:48.494249Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "b85e04e786cf0674",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "7c6feaef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T02:15:48.650569Z",
     "start_time": "2025-10-27T02:15:48.576420Z"
    }
   },
   "source": [
    "# Convert data to a dataframe\n",
    "db = pd.read_csv(\"data-words/train.tsv\", sep='\\t')\n",
    "db = db.dropna()\n",
    "db"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       Identification  O\n",
       "0                  of  O\n",
       "1                APC2  O\n",
       "2                   ,  O\n",
       "3                   a  O\n",
       "4           homologue  O\n",
       "...               ... ..\n",
       "135994            and  O\n",
       "135995      increased  O\n",
       "135996       survival  O\n",
       "135997              .  O\n",
       "135998              .  O\n",
       "\n",
       "[135971 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identification</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>APC2</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>homologue</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135994</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135995</th>\n",
       "      <td>increased</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135996</th>\n",
       "      <td>survival</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135997</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135998</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135971 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "5877278b",
   "metadata": {},
   "source": [
    "# TANL"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating a function which inputs the search term and the database. It then looks up for the term for documents and returns the list of the documents. These documents will be used by the LLm as a context for identifying entities.",
   "id": "ed71ef8a0a60aa0d"
  },
  {
   "cell_type": "code",
   "id": "2d086b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T02:15:48.695587Z",
     "start_time": "2025-10-27T02:15:48.691780Z"
    }
   },
   "source": [
    "\n",
    "def get_context(search_term,search_db):\n",
    "\n",
    "    BASE_URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
    "\n",
    "    esearch_url = BASE_URL + \"esearch.fcgi\"\n",
    "\n",
    "    esearch_params = {\n",
    "        \"db\": search_db,\n",
    "        \"term\": search_term,\n",
    "        \"retmax\": 5,\n",
    "        \"retmode\": \"json\",\n",
    "        \"usehistory\": \"y\",\n",
    "        \"tool\": \"MyPubMedAPIScript\",\n",
    "        \"email\": os.getenv(\"email\"),\n",
    "        \"api_key\": os.getenv(\"ncbi_token\")\n",
    "    }\n",
    "\n",
    "    response = requests.get(esearch_url,params=esearch_params)\n",
    "    response.raise_for_status\n",
    "\n",
    "    result_json = response.json()\n",
    "\n",
    "    result = result_json.get(\"esearchresult\",{})\n",
    "    ids = result.get(\"idlist\",[])\n",
    "    count = result.get(\"count\",0)\n",
    "    webenv = result.get(\"webenv\")\n",
    "\n",
    "    final_result = {\"search term\": search_term,\n",
    "                    \"total results:\": count,\n",
    "                    \"id list\": ids,\n",
    "                    \"web environment\": webenv}\n",
    "\n",
    "\n",
    "    return final_result\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating a test for testing the first chunk with 1500 words\n",
    "### Results:- Best performance with 25 batch size"
   ],
   "id": "dea1354a02718f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T02:17:37.727328Z",
     "start_time": "2025-10-27T02:15:48.744906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Writing the prompt usning TANL technique\n",
    "\n",
    "current_words = db[\"Identification\"].iloc[0:1500]\n",
    "current_text = \" \".join(current_words)\n",
    "\n",
    "prompt_first_classification = [\n",
    "  {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are an expert in medical domain. Given the following document, your task is to identify that it could potentially be a medical entity, do not add any other text just return the output format specified. The output should be a list of strings where the strings will be the potential medical entities nothing else, for example: the output format should be: ['entity 1', 'entity 2' ... and so on]\"\n",
    "     },\n",
    "    {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"data: {current_text}\"\n",
    "    },\n",
    "    ]\n",
    "\n",
    "prompt = pipe.tokenizer.apply_chat_template(prompt_first_classification, tokenize=False, add_generation_prompt=True)\n",
    "test_entities_from_doc = pipe(prompt,\n",
    "        max_new_tokens=1000,\n",
    "        temperature=0.1,\n",
    "        batch_size=16,\n",
    "        return_full_text=False)"
   ],
   "id": "88ad89bb78c07717",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T02:17:37.837128Z",
     "start_time": "2025-10-27T02:17:37.834375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_result_preclassification = ast.literal_eval(test_entities_from_doc[0][\"generated_text\"])\n",
    "print(test_result_preclassification)"
   ],
   "id": "f06b6713356a85ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adenomatous polyposis coli', 'Wnt signalling pathway', 'glycogen synthase kinase 3beta', 'axin/conductin', 'betacatenin', 'Tcf-4 transcription factor', 'MSH2 mutation', 'hereditary non-polyposis cancer syndrome', 'HNPCC', 'colorectal cancer', 'Huntington disease', 'apolipoprotein E', 'CAG repeat length', 'complement component 7', 'Neisseria', 'cartilage-hair hypoplasia', 'dihydropyrimidine dehydrogenase deficiency']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Final LLM calling for the entire document",
   "id": "cd64c257915d61ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating chinks of the column of size 1500 and adding them to the list of prompts",
   "id": "8a3bb532cca6591"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T02:17:37.875663Z",
     "start_time": "2025-10-27T02:17:37.872917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Writing the prompt usning TANL technique\n",
    "#\n",
    "# chunks = 1500\n",
    "# overlap = 200\n",
    "# all_potential_entities = set()\n",
    "# all_prompts = []\n",
    "#\n",
    "# for i in range(0,len(db[\"Identification\"]),chunks-overlap):\n",
    "#\n",
    "#         current_words = db[\"Identification\"][i:i+chunks]\n",
    "#         current_text = \" \".join(current_words)\n",
    "#\n",
    "#         prompt_tanl = [\n",
    "#             {\n",
    "#               \"role\": \"system\",\n",
    "#               \"content\": \"You are an expert in medical domain. Given the following document, your task is to identify that it could potentially be a medical entity, do not add any other text just return the output format specified. The output should be a list of strings where the strings will be the potential medical entities nothing else, for example: the output format should be: ['entity 1', 'entity 2' ... and so on]\"\n",
    "#                         },\n",
    "#                 {\n",
    "#                  \"role\": \"user\",\n",
    "#                  \"content\": f\"data: {current_text}\"\n",
    "#                 },\n",
    "#                 ]\n",
    "#\n",
    "#         prompt = pipe.tokenizer.apply_chat_template(prompt_tanl, tokenize=False, add_generation_prompt=True)\n",
    "#         all_prompts.append(prompt)\n",
    "#\n",
    "# print(\"All prompts added\")\n",
    "# pipe.tokenizer.pad_token = pipe.tokenizer.eos_token\n"
   ],
   "id": "4224fdbcdd260c83",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calling the pipeline",
   "id": "62d76f164b3fe498"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T02:17:37.895832Z",
     "start_time": "2025-10-27T02:17:37.893133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# entities_from_doc = pipe(all_prompts,\n",
    "#         max_new_tokens=1024,\n",
    "#         temperature=0.1,\n",
    "#         return_full_text=False,\n",
    "#         batch_size=8)"
   ],
   "id": "c31a3af1b27d7a98",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Implimenting the RAG",
   "id": "638e630215931fd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T04:10:06.781746Z",
     "start_time": "2025-10-27T04:10:06.774065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Bio import Entrez\n",
    "from urllib.error import HTTPError\n",
    "Entrez.email = \"atripathi2024@fau.edu\""
   ],
   "id": "1bfbb36365d6083d",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T04:20:48.720489Z",
     "start_time": "2025-10-27T04:20:48.711151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ragpredict(test_result_preclassification):\n",
    "\n",
    "    predictions = []\n",
    "    for i in test_result_preclassification:\n",
    "       search_term = i\n",
    "       ids = get_context(i,\"pubmed\")\n",
    "       valid_ids = [str(j) for j in ids if j]\n",
    "       context_xml = \"\"\n",
    "       if valid_ids:\n",
    "           try:\n",
    "               list_of_ids = \",\".join(valid_ids)\n",
    "               handle = Entrez.efetch(db=\"pubmed\", id=list_of_ids, retmode=\"xml\")\n",
    "               context_xml = handle.read()\n",
    "               handle.close()\n",
    "           except HTTPError as e:\n",
    "               print(f\"HTTP Error fetching IDs for term '{search_term}': {e}\")\n",
    "               pass\n",
    "           except Exception as e:\n",
    "               print(f\"An error occurred for term '{search_term}': {e}\")\n",
    "               pass\n",
    "\n",
    "\n",
    "\n",
    "       prompt_final_classification = [\n",
    "        {\n",
    "          \"role\": \"system\",\n",
    "          \"content\": \"You are an expert in medical domain. Given the following word, and a context which has been taken from Pubmed clinical database, your task is to identify that it could potentially be a medical entity, do not add any other text just return the output format specified. The output should be either 'o'- which represents outside clinical term (for non clinical terms), 'B-CLINICAL'- for the words which are beginning of a clinical term and 'I-CLINICAL' - for the words which can be a subset of a clinical term \"\n",
    "        },\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": f\"word: {search_term}, context: {context_xml}\"\n",
    "        },\n",
    "        ]\n",
    "       result = pipe(prompt_final_classification,\n",
    "                     max_new_tokens=1000,\n",
    "                     temperature=0.1,\n",
    "                     return_full_text=False\n",
    "                     )\n",
    "       result = result[0][\"generated_text\"]\n",
    "       result_dict = {\n",
    "           search_term: result\n",
    "       }\n",
    "       predictions.append(result_dict)\n",
    "\n",
    "    return  predictions\n",
    "\n",
    "\n"
   ],
   "id": "1ab3caac0770f288",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T04:21:21.928297Z",
     "start_time": "2025-10-27T04:20:52.092303Z"
    }
   },
   "cell_type": "code",
   "source": "predictions = ragpredict(test_result_preclassification)",
   "id": "c2bd42f94bef1010",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'adenomatous polyposis coli': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'Wnt signalling pathway': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'glycogen synthase kinase 3beta': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'axin/conductin': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'betacatenin': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'Tcf-4 transcription factor': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'MSH2 mutation': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'hereditary non-polyposis cancer syndrome': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'HNPCC': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'colorectal cancer': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'Huntington disease': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'apolipoprotein E': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'CAG repeat length': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'complement component 7': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'Neisseria': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'cartilage-hair hypoplasia': HTTP Error 400: Bad Request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error fetching IDs for term 'dihydropyrimidine dehydrogenase deficiency': HTTP Error 400: Bad Request\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T04:21:28.590435Z",
     "start_time": "2025-10-27T04:21:28.580404Z"
    }
   },
   "cell_type": "code",
   "source": "print(predictions)",
   "id": "2a3838ed8d646f16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'adenomatous polyposis coli': 'B-CLINICAL \\nI-CLINICAL'}, {'Wnt signalling pathway': 'B-I-CLINICAL'}, {'glycogen synthase kinase 3beta': 'B'}, {'axin/conductin': 'B-CLINICAL'}, {'betacatenin': 'B-I-CLINICAL'}, {'Tcf-4 transcription factor': 'B-CLINICAL'}, {'MSH2 mutation': 'B-CLINICAL'}, {'hereditary non-polyposis cancer syndrome': 'B-CLINICAL \\nI-CLINICAL \\nI-CLINICAL'}, {'HNPCC': 'B'}, {'colorectal cancer': 'B-CLINICAL \\nI-CLINICAL \\nI-CLINICAL'}, {'Huntington disease': 'B-Hunting'}, {'apolipoprotein E': 'B-CLINICAL'}, {'CAG repeat length': 'B-CLINICAL'}, {'complement component 7': 'B-CLINICAL'}, {'Neisseria': 'B-CLINICAL'}, {'cartilage-hair hypoplasia': 'B-CLINICAL'}, {'dihydropyrimidine dehydrogenase deficiency': 'B-CLINICAL'}]\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T04:23:56.706974Z",
     "start_time": "2025-10-27T04:23:56.690669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reformatted_data = [{'Term': list(item.keys())[0], 'Classification': list(item.values())[0]} for item in predictions]\n",
    "predictions_data= pd.DataFrame(reformatted_data)\n",
    "predictions_data"
   ],
   "id": "9aae6ae0d17b5b25",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                          Term  \\\n",
       "0                   adenomatous polyposis coli   \n",
       "1                       Wnt signalling pathway   \n",
       "2               glycogen synthase kinase 3beta   \n",
       "3                               axin/conductin   \n",
       "4                                  betacatenin   \n",
       "5                   Tcf-4 transcription factor   \n",
       "6                                MSH2 mutation   \n",
       "7     hereditary non-polyposis cancer syndrome   \n",
       "8                                        HNPCC   \n",
       "9                            colorectal cancer   \n",
       "10                          Huntington disease   \n",
       "11                            apolipoprotein E   \n",
       "12                           CAG repeat length   \n",
       "13                      complement component 7   \n",
       "14                                   Neisseria   \n",
       "15                   cartilage-hair hypoplasia   \n",
       "16  dihydropyrimidine dehydrogenase deficiency   \n",
       "\n",
       "                          Classification  \n",
       "0                B-CLINICAL \\nI-CLINICAL  \n",
       "1                           B-I-CLINICAL  \n",
       "2                                      B  \n",
       "3                             B-CLINICAL  \n",
       "4                           B-I-CLINICAL  \n",
       "5                             B-CLINICAL  \n",
       "6                             B-CLINICAL  \n",
       "7   B-CLINICAL \\nI-CLINICAL \\nI-CLINICAL  \n",
       "8                                      B  \n",
       "9   B-CLINICAL \\nI-CLINICAL \\nI-CLINICAL  \n",
       "10                             B-Hunting  \n",
       "11                            B-CLINICAL  \n",
       "12                            B-CLINICAL  \n",
       "13                            B-CLINICAL  \n",
       "14                            B-CLINICAL  \n",
       "15                            B-CLINICAL  \n",
       "16                            B-CLINICAL  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adenomatous polyposis coli</td>\n",
       "      <td>B-CLINICAL \\nI-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wnt signalling pathway</td>\n",
       "      <td>B-I-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>glycogen synthase kinase 3beta</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>axin/conductin</td>\n",
       "      <td>B-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>betacatenin</td>\n",
       "      <td>B-I-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tcf-4 transcription factor</td>\n",
       "      <td>B-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSH2 mutation</td>\n",
       "      <td>B-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hereditary non-polyposis cancer syndrome</td>\n",
       "      <td>B-CLINICAL \\nI-CLINICAL \\nI-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HNPCC</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>colorectal cancer</td>\n",
       "      <td>B-CLINICAL \\nI-CLINICAL \\nI-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Huntington disease</td>\n",
       "      <td>B-Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>apolipoprotein E</td>\n",
       "      <td>B-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CAG repeat length</td>\n",
       "      <td>B-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>complement component 7</td>\n",
       "      <td>B-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Neisseria</td>\n",
       "      <td>B-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cartilage-hair hypoplasia</td>\n",
       "      <td>B-CLINICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dihydropyrimidine dehydrogenase deficiency</td>\n",
       "      <td>B-CLINICAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "id": "a98afd48",
   "metadata": {},
   "source": [
    "# Dice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
